<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; --monospace: "Lucida Console",Consolas,"Courier",monospace; --title-bar-height: 20px; }
.mac-os-11 { --title-bar-height: 28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex: 2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }
.md-alert.md-alert-note { border-left-color: rgb(9, 105, 218); }
.md-alert.md-alert-important { border-left-color: rgb(130, 80, 223); }
.md-alert.md-alert-warning { border-left-color: rgb(154, 103, 0); }
.md-alert.md-alert-tip { border-left-color: rgb(31, 136, 61); }
.md-alert.md-alert-caution { border-left-color: rgb(207, 34, 46); }
.md-alert { padding: 0px 1em; margin-bottom: 16px; color: inherit; border-left: 0.25em solid rgb(0, 0, 0); }
.md-alert-text-note { color: rgb(9, 105, 218); }
.md-alert-text-important { color: rgb(130, 80, 223); }
.md-alert-text-warning { color: rgb(154, 103, 0); }
.md-alert-text-tip { color: rgb(31, 136, 61); }
.md-alert-text-caution { color: rgb(207, 34, 46); }
.md-alert-text { font-size: 0.9rem; font-weight: 700; }
.md-alert-text svg { fill: currentcolor; position: relative; top: 0.125em; margin-right: 1ch; overflow: visible; }
.md-alert-text-container::after { content: attr(data-text); text-transform: capitalize; pointer-events: none; margin-right: 1ch; }


:root {
    --side-bar-bg-color: #fafafa;
    --control-text-color: #777;
}

@include-when-export url(https://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext);

/* open-sans-regular - latin-ext_latin */
  /* open-sans-italic - latin-ext_latin */
    /* open-sans-700 - latin-ext_latin */
    /* open-sans-700italic - latin-ext_latin */
  html {
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
}

body {
    font-family: "Open Sans","Clear Sans", "Helvetica Neue", Helvetica, Arial, 'Segoe UI Emoji', sans-serif;
    color: rgb(51, 51, 51);
    line-height: 1.6;
}

#write {
    max-width: 860px;
  	margin: 0 auto;
  	padding: 30px;
    padding-bottom: 100px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1024px;
	}
}

@media only screen and (min-width: 1800px) {
	#write {
		max-width: 1200px;
	}
}

#write > ul:first-child,
#write > ol:first-child{
    margin-top: 30px;
}

a {
    color: #4183C4;
}
h1,
h2,
h3,
h4,
h5,
h6 {
    position: relative;
    margin-top: 1rem;
    margin-bottom: 1rem;
    font-weight: bold;
    line-height: 1.4;
    cursor: text;
}
h1:hover a.anchor,
h2:hover a.anchor,
h3:hover a.anchor,
h4:hover a.anchor,
h5:hover a.anchor,
h6:hover a.anchor {
    text-decoration: none;
}
h1 tt,
h1 code {
    font-size: inherit;
}
h2 tt,
h2 code {
    font-size: inherit;
}
h3 tt,
h3 code {
    font-size: inherit;
}
h4 tt,
h4 code {
    font-size: inherit;
}
h5 tt,
h5 code {
    font-size: inherit;
}
h6 tt,
h6 code {
    font-size: inherit;
}
h1 {
    font-size: 2.25em;
    line-height: 1.2;
    border-bottom: 1px solid #eee;
}
h2 {
    font-size: 1.75em;
    line-height: 1.225;
    border-bottom: 1px solid #eee;
}

/*@media print {
    .typora-export h1,
    .typora-export h2 {
        border-bottom: none;
        padding-bottom: initial;
    }

    .typora-export h1::after,
    .typora-export h2::after {
        content: "";
        display: block;
        height: 100px;
        margin-top: -96px;
        border-top: 1px solid #eee;
    }
}*/

h3 {
    font-size: 1.5em;
    line-height: 1.43;
}
h4 {
    font-size: 1.25em;
}
h5 {
    font-size: 1em;
}
h6 {
   font-size: 1em;
    color: #777;
}
p,
blockquote,
ul,
ol,
dl,
table{
    margin: 0.8em 0;
}
li>ol,
li>ul {
    margin: 0 0;
}
hr {
    height: 2px;
    padding: 0;
    margin: 16px 0;
    background-color: #e7e7e7;
    border: 0 none;
    overflow: hidden;
    box-sizing: content-box;
}

li p.first {
    display: inline-block;
}
ul,
ol {
    padding-left: 30px;
}
ul:first-child,
ol:first-child {
    margin-top: 0;
}
ul:last-child,
ol:last-child {
    margin-bottom: 0;
}
blockquote {
    border-left: 4px solid #dfe2e5;
    padding: 0 15px;
    color: #777777;
}
blockquote blockquote {
    padding-right: 0;
}
table {
    padding: 0;
    word-break: initial;
}
table tr {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 0;
}
table tr:nth-child(2n),
thead {
    background-color: #f8f8f8;
}
table th {
    font-weight: bold;
    border: 1px solid #dfe2e5;
    border-bottom: 0;
    margin: 0;
    padding: 6px 13px;
}
table td {
    border: 1px solid #dfe2e5;
    margin: 0;
    padding: 6px 13px;
}
table th:first-child,
table td:first-child {
    margin-top: 0;
}
table th:last-child,
table td:last-child {
    margin-bottom: 0;
}

.CodeMirror-lines {
    padding-left: 4px;
}

.code-tooltip {
    box-shadow: 0 1px 1px 0 rgba(0,28,36,.3);
    border-top: 1px solid #eef2f2;
}

.md-fences,
code,
tt {
    border: 1px solid #e7eaed;
    background-color: #f8f8f8;
    border-radius: 3px;
    padding: 0;
    padding: 2px 4px 0px 4px;
    font-size: 0.9em;
}

code {
    background-color: #f3f4f4;
    padding: 0 2px 0 2px;
}

.md-fences {
    margin-bottom: 15px;
    margin-top: 15px;
    padding-top: 8px;
    padding-bottom: 6px;
}


.md-task-list-item > input {
  margin-left: -1.3em;
}

@media print {
    html {
        font-size: 13px;
    }
    pre {
        page-break-inside: avoid;
        word-wrap: break-word;
    }
}

.md-fences {
	background-color: #f8f8f8;
}
#write pre.md-meta-block {
	padding: 1rem;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f7f7f7;
    border: 0;
    border-radius: 3px;
    color: #777777;
    margin-top: 0 !important;
}

.mathjax-block>.code-tooltip {
	bottom: .375rem;
}

.md-mathjax-midline {
    background: #fafafa;
}

#write>h3.md-focus:before{
	left: -1.5625rem;
	top: .375rem;
}
#write>h4.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h5.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
#write>h6.md-focus:before{
	left: -1.5625rem;
	top: .285714286rem;
}
.md-image>.md-meta {
    /*border: 1px solid #ddd;*/
    border-radius: 3px;
    padding: 2px 0px 0px 4px;
    font-size: 0.9em;
    color: inherit;
}

.md-tag {
    color: #a7a7a7;
    opacity: 1;
}

.md-toc { 
    margin-top:20px;
    padding-bottom:20px;
}

.sidebar-tabs {
    border-bottom: none;
}

#typora-quick-open {
    border: 1px solid #ddd;
    background-color: #f8f8f8;
}

#typora-quick-open-item {
    background-color: #FAFAFA;
    border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee;
    border-style: solid;
    border-width: 1px;
}

/** focus mode */
.on-focus-mode blockquote {
    border-left-color: rgba(85, 85, 85, 0.12);
}

header, .context-menu, .megamenu-content, footer{
    font-family: "Segoe UI", "Arial", sans-serif;
}

.file-node-content:hover .file-node-icon,
.file-node-content:hover .file-node-open-state{
    visibility: visible;
}

.mac-seamless-mode #typora-sidebar {
    background-color: #fafafa;
    background-color: var(--side-bar-bg-color);
}

.mac-os #write{
    caret-color: AccentColor;
}

.md-lang {
    color: #b4654d;
}

/*.html-for-mac {
    --item-hover-bg-color: #E6F0FE;
}*/

#md-notification .btn {
    border: 0;
}

.dropdown-menu .divider {
    border-color: #e5e5e5;
    opacity: 0.4;
}

.ty-preferences .window-content {
    background-color: #fafafa;
}

.ty-preferences .nav-group-item.active {
    color: white;
    background: #999;
}

.menu-item-container a.menu-style-btn {
    background-color: #f5f8fa;
    background-image: linear-gradient( 180deg , hsla(0, 0%, 100%, 0.8), hsla(0, 0%, 100%, 0)); 
}



</style><title>VLA</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><h1 id='vision-language-action-models'><span>Vision-Language-Action Models</span></h1><ul><li><p><span>Google 的 DeepMind 团队基于互联网上数据训练视觉-语言模型（VLM），使其能够学习到视觉和语言之间映射关系的知识，在机器人操纵任务上微调</span></p></li></ul><h2 id='rt-1'><span>RT-1</span></h2><ul><li><p><span>论文2022年12月13日上传至 arXiv </span><a href='https://arxiv.org/abs/2212.06817' target='_blank' class='url'>https://arxiv.org/abs/2212.06817</a></p></li><li><p><span>代码2022年12月10日上传至 Github </span><a href='https://github.com/google-research/robotics_transformer' target='_blank' class='url'>https://github.com/google-research/robotics_transformer</a></p></li></ul><h3 id='概述'><span>概述</span></h3><ul><li><p><strong><span>Robot</span></strong><span>：用于RT-1 研究的机器人有7个自由度的机械臂、两个手指型夹抓，以及一个移动基座</span></p></li><li><p><strong><span>Dataset</span></strong><span>：17个月的时间内收集了13个机器人的〜130k 个片段和700多个任务数据</span></p></li><li><p><strong><span>Input / Output</span></strong><span>：采用</span><strong><span>图像和自然语言指令</span></strong><span>，并输出</span><strong><span>离散的基础和手臂动作</span></strong><span>，包括：</span><strong><span>手臂运动的七个维度</span></strong><span>（x、 y、z、滚动、俯仰、侧滑、夹具打开），</span><strong><span>基本运动的三个维度</span></strong><span>（X，Y，侧滑）和一个离散的维度，可以在三种模式之间切换：控制手臂，底座或终止动作。 RT-1执行闭环控制，并以 </span><strong><span>3 Hz</span></strong><span>的速度命令操作，直到它产生“终止”动作或达到预设的时间步长限制为止</span></p></li><li><p><strong><span>Architecture</span></strong><span>：FiLM EfficientNet + TokenLearner + Transformer = </span><strong><span>35M</span></strong><span> parameters</span></p></li><li><p><strong><span>Method</span></strong><span>：在该数据集的基础之上，基于模仿学习中</span><strong><span>行为克隆学习范式</span></strong><span>，把 Transformer 应用机器人的操纵任务上，提出了 RT-1模型</span></p></li><li><p><strong><span>Success</span></strong><span>：RT-1可以以</span><strong><span>97％的成功率</span></strong><span>执行700多种指令，可以推广到新的任务、干扰因素和背景，比下一个最佳基线分别高25%、36%和18%</span></p></li><li><p><strong><span>Limitation</span></strong><span>：依赖真实机器人数据，强于已知任务，但</span><strong><span>泛化能力有限</span></strong></p></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250326170857873.png" referrerpolicy="no-referrer" alt="image-20250326170857873"></p><h3 id='模型架构'><span>模型架构</span></h3><figure class='table-figure'><table><thead><tr><th><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250326171118137.png" referrerpolicy="no-referrer" alt="image-20250326171118137"></th><th><strong><span>Instruction and Image Tokenization</span></strong><span>（16M）：</span><br /><span>6 幅300×300的图像输入预训练EfficientNet-B3进行tokenize ，利用最终卷积层输出的9×9×512的空间特征图，形成81个tokens</span><br /><br /><strong><span>TokenLearner</span></strong><span>：</span><br /><span>将81个视觉令牌子采样为8个最终令牌，然后传递给Transformer层</span><br /><br /><span>Transformer（19M）</span><br /><span>将每个图像的这8个令牌与其他图像连接起来，形成总共48个令牌（添加了位置编码），馈送到RT-1的Transformer骨干中</span><br /><br /><strong><span>Action Tokenization</span></strong><br /><span>RT-1中的每个动作维度都被离散化为256个bins，每个bin在对应变量的边界内均匀分布</span><br /><br /><strong><span>Loss</span></strong><br /><span>标准分类交叉熵熵和causal masking</span><br /><br /></th></tr></thead><tbody></tbody></table></figure><h3 id='表现'><span>表现</span></h3><ul><li><p><strong><span>Generalization</span></strong><span>：</span></p><ul><li><p><strong><span>Seen Tasks</span></strong><span>：执行 200+ 个指令，成功率达 97%</span></p></li><li><p><strong><span>Unseen Tasks</span></strong><span>：成功率达76％，比下一最佳 baseline（Gato）高 24％</span></p></li></ul></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327091207599.png" referrerpolicy="no-referrer" alt="image-20250327091207599"></p><ul><li><p><strong><span>Robustness</span></strong><span>：</span></p><ul><li><p><strong><span>Distractors</span></strong><span>（干扰）：包含2至4个干扰物对象。在最具挑战性的情况下，场景非常混乱，并包含感兴趣的对象的遮挡</span></p></li></ul></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327092236149.png" referrerpolicy="no-referrer" alt="image-20250327092236149"></p><ul><li><p><strong><span>Backgrounds</span></strong><span>（背景）：测试RT-1在具有不同桌面纹理和不同背景的设置上的性能</span></p></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327092202737.png" referrerpolicy="no-referrer" alt="image-20250327092202737"></p><p>&nbsp;</p><h2 id='rt-2'><span>RT-2</span></h2><ul><li><p><span>论文2023年07月28日上传至 arXiv </span><a href='https://arxiv.org/abs/2307.15818' target='_blank' class='url'>https://arxiv.org/abs/2307.15818</a></p></li><li><p><span>CoRL 2023 接收</span></p></li></ul><h3 id='概述-2'><span>概述</span></h3><ul><li><p><strong><span>Method</span></strong><span>：提出了一个在机器人轨迹数据和互联网级别的视觉语言任务 </span><strong><span>联合微调 VLM</span></strong><span> 的学习方式，产生的模型被称为 </span><strong><span>Vision-Language-Action（VLA）Models</span></strong><span>。</span><strong><span>将机器人动作表示为另一种语言</span></strong><span>，可以将其施加到 Text Tokens 中，并与视觉语言数据集进行训练。在推理过程中，Text Tokens 被 </span><strong><span>De-Tokenize 为机器人动作</span></strong><span>，从而实现</span><strong><span>闭环控制（Close-Loop Control）</span></strong></p></li><li><p><strong><span>Difference from RT-1</span></strong><span>：RT-1 是利用预训练模型对视觉与语言进行编码，然后再通过解码器输出动作。 RT-2 则是把语言、动作、图片放在一个统一的输出空间，利用 VLMs 产生动作”语言“。</span></p></li><li><p><strong><span>Limitation</span></strong><span>：机器人能够成功做出的动作已经是预先设计好的，VLM 只是能够帮助机器人选择合适的任务规划</span></p></li></ul><p><span>注：</span><strong><span>Close-Loop Control</span></strong><span>：</span><strong><span>将控制系统输出量</span></strong><span>的一部分或全部，通过一定方法和装置</span><strong><span>反送回系统的输入端</span></strong><span>，然后将反馈信息与原输入信息进行比较，再</span><strong><span>将比较的结果施加于系统进行控制</span></strong><span>，避免系统偏离预定目标。</span></p><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250326170926104.png" referrerpolicy="no-referrer" alt="image-20250326170926104"></p><h3 id='模型架构-2'><span>模型架构</span></h3><ul><li><p><strong><span>Pre-Trained VLMs</span></strong><span>：采用 Pathways Language and Image （Pali-X） 和 Pathways Language Model Embodied（Palm-E）。单纯的视觉语言模型可以通过</span><strong><span>网络级的数据</span></strong><span>训练出来，因为数据量足够大，能够得到足够好的效果</span></p></li></ul><ul><li><p><strong><span>Action Tokenization</span></strong><span>：同 RT-1 中的离散化编码，每个动作维度都被离散化为256个bins</span></p></li><li><p><strong><span>Action Space</span></strong><span>：动作空间包括机器人末端执行器的</span><strong><span>6-DoF位置和旋转位移</span></strong><span>，以及机器人</span><strong><span>夹具的延伸</span></strong><span>水平和</span><strong><span>用于终止事件的特殊离散命令</span></strong><span>，该命令应由策略触发以表示成功完成。连续维度（除离散终止命令外的所有维度）被均匀地离散化为256个区间。因此，可以用</span><strong><span>8个数字来表示一个动作</span></strong></p></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327103434640.png" referrerpolicy="no-referrer" alt="image-20250327103434640"></p><p>&nbsp;</p><h3 id='表现-2'><span>表现</span></h3><ul><li><p><strong><span>Generalization</span></strong><span>：</span></p><ul><li><p><strong><span>Seen Tasks</span></strong><span>：RT-1 和 RT-2 的表现接近</span></p></li><li><p><strong><span>Unseen Tasks</span></strong><span>：较下一最佳baseline，有约 </span><strong><span>2倍</span></strong><span> 的提升</span></p></li></ul></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327104722393.png" referrerpolicy="no-referrer" alt="image-20250327104722393"></p><ul><li><p><strong><span>Emergent Capabilities</span></strong><span>：</span></p></li></ul><p><span>	</span><span>例如：将草莓放入</span><strong><span>正确的碗</span></strong><span>中 / 拿起即将掉下桌子的袋子</span></p><figure class='table-figure'><table><thead><tr><th><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327105636088.png" referrerpolicy="no-referrer" alt="image-20250327105636088"></th><th><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327105817536.png" referrerpolicy="no-referrer" alt="image-20250327105817536"></th></tr></thead><tbody></tbody></table></figure><ul><li><p><strong><span>参数量和训练策略的影响</span></strong><span>：</span></p><ul><li><p><strong><span>参数量</span></strong><span>：RT-2-PaLI-X 的 </span><strong><span>5B</span></strong><span> 和 </span><strong><span>55B</span></strong><span> 模型</span></p></li><li><p><strong><span>训练策略</span></strong><span>：1）</span><strong><span>从头开始训练</span></strong><span>模型，不使用 VLM 预训练权重；2）</span><strong><span>仅使用机器人动作数据</span></strong><span>微调预训练模型；3）</span><strong><span>联合微调</span></strong><span>（与视觉语言任务共同微调）</span></p></li></ul></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327110050744.png" referrerpolicy="no-referrer" alt="image-20250327110050744"></p><ul><li><p><strong><span>Chain-of-Thought Reasoning</span></strong><span>：推出具有</span><strong><span>思维链推理</span></strong><span>的 RT-2，生成</span><strong><span>每一步的计划和行动</span></strong></p></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327110556847.png" referrerpolicy="no-referrer" alt="image-20250327110556847"></p><p>&nbsp;</p><h2 id='openvla'><span>OpenVLA</span></h2><ul><li><p><span>作者：</span><a href='https://moojink.com/' target='_blank' class='url'>https://moojink.com/</a></p></li><li><p><span>论文2024年06月13日上传至 arXiv </span><a href='https://arxiv.org/abs/2406.09246' target='_blank' class='url'>https://arxiv.org/abs/2406.09246</a></p></li><li><p><span>CoRL 2024 接收</span></p></li></ul><h3 id='与-rt-2-比较'><span>与 RT-2 比较</span></h3><ul><li><p><strong><span>Smaller Size</span></strong><span>：OpenVLA 的参数量（7B）仅为 RT-2-X（55B）的大约</span><strong><span>七分之一</span></strong></p></li></ul><ul><li><p><span>稳健性：</span></p></li><li><p><span>鲁棒性：当机械臂末端受到随机</span><strong><span>外力干扰</span></strong><span>时，OpenVLA的</span><strong><span>轨迹恢复速度</span></strong><span>比RT-2快 40%</span></p></li><li><p><strong><span>Open-Source</span></strong><span>：</span></p></li></ul><h3 id='概述-3'><span>概述</span></h3><ul><li><p><strong><span>Robot</span></strong><span>：在</span><strong><span>两个不同的机器人</span></strong><span>平台上进行了“开箱即用”的评估，BridgeData V2中使用的 </span><strong><span>WidowX</span></strong><span> 和 RT-2中所使用的平台</span></p></li><li><p><strong><span>Dataset</span></strong><span>：Open X-Embodiment数据集，这是一个包含超过70个独立机器人数据集的大规模集合，拥有超过200万条机器人轨迹</span></p></li><li><p><strong><span>Input / Output</span></strong><span>：接收图像观察和语言指令，预测7维的机器人控制动作</span></p></li><li><p><strong><span>Architecture</span></strong><span>：</span></p><ul><li><p><strong><span>视觉编码器</span></strong><span>：Prismatic-7B VLM，结合了Dino V2 和 SigLIP 的特征，将图像输入映射为一系列&quot;图像patch嵌入&quot;</span></p></li><li><p><strong><span>投影器</span></strong><span>：将视觉特征映射到语言嵌入空间</span></p></li><li><p><strong><span>LLM</span></strong><span>：基于70亿参数的Llama 2大型语言模型，处理来自视觉和语言数据的配对或交错输入，并通过预测下一个文本token进行端到端训练</span></p></li></ul></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250326170836893.png" referrerpolicy="no-referrer" alt="image-20250326170836893"></p><h3 id='模型架构-3'><span>模型架构</span></h3><ul><li><p><strong><span>Action Tokenization</span></strong><span>：继承了 RT-1 和 RT-2 中的离散化编码。在其基础上，</span><strong><span>使用动作数据的1%至99%分位数之间的均匀间隔来设置每个bin的宽度</span></strong><span>，而不是最小值和最大值（</span><u><span>RT-1中提出每个bin在对应变量的边界内均匀分布</span></u><span>），这样可以</span><strong><span>忽略掉可能大幅扩展离散化区间的数据异常值</span></strong><span>，从而保持较高的离散化精度</span></p><ul><li><p><span>关于这一操作的原理和作用，以下回答来自 </span><strong><span>DeepSeek</span></strong><span>：</span></p></li><li><p><strong><span>核心原理</span></strong><span>：使用</span><strong><span>1%和99%分位数</span></strong><span>作为区间边界，本质上是基于数据分布的</span><strong><span>鲁棒性统计</span></strong><span>。1）</span><strong><span>排除极端值</span></strong><span>：过滤掉数据中前1%和后1%的异常值，保留中间98%的主体数据；2）</span><strong><span>自适应数据分布</span></strong><span>：分位数直接反映数据的实际密度分布，确保离散化区间覆盖</span><strong><span>高频动作区域</span></strong></p></li><li><p><strong><span>实际意义和优势</span></strong><span>：1）</span><strong><span>增强模型鲁棒性</span></strong><span>：避免异常值对离散化的干扰；2）</span><strong><span>提升动作分辨率</span></strong><span>：在数据密集区域（如中间98%区间）分配更多精细的bins，使模型能区分更细微的动作差异；3）</span><strong><span>数据效率优化</span></strong><span>：更高效地利用数据分布信息，避免因极端值导致的无效区间划分；4）</span><strong><span>泛化能力提升</span></strong><span>：测试时遇到的动作值更可能落在训练见过的bins中，减少外推误差</span></p></li><li><p><strong><span>总结</span></strong><span>：OpenVLA的离散化策略本质是</span><strong><span>以数据驱动代替先验假设</span></strong><span>，通过分位数排除离群值干扰，聚焦于真实数据分布的核心区域。这不仅提升了动作编码的效率和精度，还增强了模型在实际场景中的鲁棒性和泛化能力，是机器人动作建模中一种更符合真实数据特性的工程优化方案</span></p></li></ul></li><li><p><strong><span>Training Procedure</span></strong><span>：采用标准的 Next-token Prediction Objective，即</span><strong><span>只评估预测的动作token上的交叉熵损失</span></strong></p></li><li><p><strong><span>VLM Backbone</span></strong><span>：可选的包括 Prismatic，fine-tuning IDEFICS-1，LLAVA，三者在初始 Bridgev2 评估中具有相似的下游性能。最终选择 Prismatic，因其通过融合的siglip-dinov2骨架提高了其空间推理能力（输入图像块分别通过</span><strong><span>两个编码器</span></strong><span>，得到的特征向量按通道连接）</span></p></li><li><p><strong><span>Fine-Tuning Vision Encoder</span></strong><span>：在 VLA 训练期间对视觉编码器进行微调对于良好的 VLA 性能至关重要</span></p></li></ul><h3 id='表现-3'><span>表现</span></h3><ul><li><p><strong><span>Robots</span></strong><span>：Widow X、Google Robot</span></p></li><li><p><strong><span>Baseline Models</span></strong><span>：RT-1-X、RT-2-X、Octo</span></p></li><li><p><strong><span>Evaluation Tasks</span></strong><span>：BridgeDataV2 的 17 个任务/10次演示，Google Robot 的12个任务/5次演示。</span></p></li><li><p><strong><span>Task Categories</span></strong><span>：视觉（未见背景、干扰物、物体的颜色和外观），运动（未见物体的位置和方向），物理（未见的物体尺寸和形状），语义（未见的目标物体、指令和来自互联网的概念）</span></p></li></ul><h4 id='与sota的对比'><span>与SOTA的对比</span></h4><figure class='table-figure'><table><thead><tr><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327161527093.png" referrerpolicy="no-referrer" alt="image-20250327161527093"></th><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327161615246.png" referrerpolicy="no-referrer" alt="image-20250327161615246"></th></tr></thead><tbody><tr><td style='text-align:center;' ><span>Bridge V2 WidowX Evaluation</span></td><td style='text-align:center;' ><span>Google Robot Evaluation</span></td></tr></tbody></table></figure><h4 id='对新机器人的适用性'><span>对新机器人的适用性</span></h4><p><span>Data-Efficient Adaptation to </span><strong><span>New Robot Setups</span></strong><span>：</span></p><ul><li><p><strong><span>Franka-Tabletop</span></strong><span>：固定安装在桌子上的 Franka Emika Panda 7 自由度机器人手臂</span></p></li><li><p><strong><span>Franka-DROID</span></strong><span>：DROID中的设置（下左图），即安装在可移动的立式桌子上</span></p></li></ul><figure class='table-figure'><table><thead><tr><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327162428444.png" referrerpolicy="no-referrer" alt="image-20250327162428444"></th><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327162047025.png" referrerpolicy="no-referrer" alt="image-20250327162047025"></th></tr></thead><tbody><tr><td style='text-align:center;' ><span>The DROID Robot Platform</span></td><td style='text-align:center;' ><span>Data-Efficient Adaptation Results</span></td></tr></tbody></table></figure><h4 id='高效微调'><span>高效微调</span></h4><ul><li><p><strong><span>Task</span></strong><span>：Multiple Franka-Tabletop</span></p></li><li><p><strong><span>Fine-tuning Approaches</span></strong><span>：</span></p><ul><li><p><strong><span>Last Layer Only</span></strong><span>：仅微调 OpenVLA 中 Transformer 骨干网的最后一层和 Token Embedding Matrix</span></p></li><li><p><strong><span>Frozen Vision</span></strong><span>：冻结视觉编码器，但微调所有其他权重</span></p></li><li><p><strong><span>Sandwich Fine-tuning</span></strong><span>：解冻了视觉编码器、Token Embedding Matrix 和最后一层</span></p></li><li><p><strong><span>LoRA</span></strong><span>：使用低秩自适应技术，改变多个秩值 r，应用于模型的所有线性层</span></p></li></ul></li><li><p><strong><span>结论</span></strong><span>：借助 LoRA，可以在 </span><strong><span>10-15 小时内在 单个 A100 GPU 上对新任务微调</span></strong><span>，与完全微调相比，</span><strong><span>计算量减少 8 倍</span></strong></p></li></ul><p><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327164812704.png" referrerpolicy="no-referrer" alt="image-20250327164812704"></p><h4 id='高效推理'><span>高效推理</span></h4><ul><li><p><strong><span>结论</span></strong><span>：4-bit 量化与 bfloat16 推理（默认方法）的性能相匹配，同时将 </span><strong><span>GPU 内存空间降低一半</span></strong><span>以上</span></p></li></ul><figure class='table-figure'><table><thead><tr><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327164828748.png" referrerpolicy="no-referrer" alt="image-20250327164828748"></th><th style='text-align:center;' ><img src="C:\Users\SvyJ\AppData\Roaming\Typora\typora-user-images\image-20250327164850926.png" referrerpolicy="no-referrer" alt="image-20250327164850926"></th></tr></thead><tbody><tr><td style='text-align:center;' ><span>Performance with Quantized Inference</span></td><td style='text-align:center;' ><span>OpenVLA Inference Speed for Various GPUs</span></td></tr></tbody></table></figure><p>&nbsp;</p></div></div>
</body>
</html>
